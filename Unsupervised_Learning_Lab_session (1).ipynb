{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "83f26a29",
      "metadata": {
        "id": "83f26a29"
      },
      "source": [
        "# Unsupervised Lab Session"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ea571d1",
      "metadata": {
        "id": "8ea571d1"
      },
      "source": [
        "## Learning outcomes:\n",
        "- Exploratory data analysis and data preparation for model building.\n",
        "- PCA for dimensionality reduction.\n",
        "- K-means and Agglomerative Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd7f778a",
      "metadata": {
        "id": "fd7f778a"
      },
      "source": [
        "## Problem Statement\n",
        "Based on the given marketing campigan dataset, segment the similar customers into suitable clusters. Analyze the clusters and provide your insights to help the organization promote their business."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33b58f8f",
      "metadata": {
        "id": "33b58f8f"
      },
      "source": [
        "## Context:\n",
        "- Customer Personality Analysis is a detailed analysis of a company’s ideal customers. It helps a business to better understand its customers and makes it easier for them to modify products according to the specific needs, behaviors and concerns of different types of customers.\n",
        "- Customer personality analysis helps a business to modify its product based on its target customers from different types of customer segments. For example, instead of spending money to market a new product to every customer in the company’s database, a company can analyze which customer segment is most likely to buy the product and then market the product only on that particular segment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867166aa",
      "metadata": {
        "id": "867166aa"
      },
      "source": [
        "## About dataset\n",
        "- Source: https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis?datasetId=1546318&sortBy=voteCount\n",
        "\n",
        "### Attribute Information:\n",
        "- ID: Customer's unique identifier\n",
        "- Year_Birth: Customer's birth year\n",
        "- Education: Customer's education level\n",
        "- Marital_Status: Customer's marital status\n",
        "- Income: Customer's yearly household income\n",
        "- Kidhome: Number of children in customer's household\n",
        "- Teenhome: Number of teenagers in customer's household\n",
        "- Dt_Customer: Date of customer's enrollment with the company\n",
        "- Recency: Number of days since customer's last purchase\n",
        "- Complain: 1 if the customer complained in the last 2 years, 0 otherwise\n",
        "- MntWines: Amount spent on wine in last 2 years\n",
        "- MntFruits: Amount spent on fruits in last 2 years\n",
        "- MntMeatProducts: Amount spent on meat in last 2 years\n",
        "- MntFishProducts: Amount spent on fish in last 2 years\n",
        "- MntSweetProducts: Amount spent on sweets in last 2 years\n",
        "- MntGoldProds: Amount spent on gold in last 2 years\n",
        "- NumDealsPurchases: Number of purchases made with a discount\n",
        "- AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n",
        "- AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n",
        "- AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n",
        "- AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n",
        "- AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n",
        "- Response: 1 if customer accepted the offer in the last campaign, 0 otherwise\n",
        "- NumWebPurchases: Number of purchases made through the company’s website\n",
        "- NumCatalogPurchases: Number of purchases made using a catalogue\n",
        "- NumStorePurchases: Number of purchases made directly in stores\n",
        "- NumWebVisitsMonth: Number of visits to company’s website in the last month"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a830406",
      "metadata": {
        "id": "5a830406"
      },
      "source": [
        "### 1. Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d65c5528",
      "metadata": {
        "id": "d65c5528"
      },
      "outputs": [],
      "source": [
        "### Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from scipy import stats\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import zscore\n",
        "from scipy.spatial import distance\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TpOfi1fyLFID"
      },
      "id": "TpOfi1fyLFID",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c80eb960",
      "metadata": {
        "id": "c80eb960"
      },
      "source": [
        "### 2. Load the CSV file (i.e marketing.csv) and display the first 5 rows of the dataframe. Check the shape and info of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1caebc10",
      "metadata": {
        "id": "1caebc10"
      },
      "outputs": [],
      "source": [
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/marketing.csv')\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get the info on the data\n",
        "df.info()"
      ],
      "metadata": {
        "id": "dDM603eRavj8"
      },
      "id": "dDM603eRavj8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the shape of the data\n",
        "df.shape"
      ],
      "metadata": {
        "id": "4hsg7uyWav-U"
      },
      "id": "4hsg7uyWav-U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9ef75724",
      "metadata": {
        "id": "9ef75724"
      },
      "source": [
        "### 3. Check the percentage of missing values? If there is presence of missing values, treat them accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c231df",
      "metadata": {
        "id": "f2c231df"
      },
      "outputs": [],
      "source": [
        "#checking if there are missing values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#percentage of missing values\n",
        "df.isnull().sum()/len(df)*100"
      ],
      "metadata": {
        "id": "TthB3mLLa_64"
      },
      "id": "TthB3mLLa_64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling the missing value\n",
        "df['Income'] = df['Income'].fillna(df['Income'].mean())\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "drd94Pu5bDb6"
      },
      "id": "drd94Pu5bDb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "86f3709e",
      "metadata": {
        "id": "86f3709e"
      },
      "source": [
        "### 4. Check if there are any duplicate records in the dataset? If any drop them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2970671a",
      "metadata": {
        "id": "2970671a"
      },
      "outputs": [],
      "source": [
        "# check for duplicate data\n",
        "len(df[df.duplicated()])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no duplicate values in the data.\n"
      ],
      "metadata": {
        "id": "xFetLytebRKT"
      },
      "id": "xFetLytebRKT"
    },
    {
      "cell_type": "markdown",
      "id": "3a6f2b5a",
      "metadata": {
        "id": "3a6f2b5a"
      },
      "source": [
        "### 5. Drop the columns which you think redundant for the analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ca818b",
      "metadata": {
        "id": "a9ca818b"
      },
      "outputs": [],
      "source": [
        "# drop the redundant columns\n",
        "df = df.drop(columns=['ID','Dt_Customer'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff0a112",
      "metadata": {
        "id": "4ff0a112"
      },
      "source": [
        "### 6. Check the unique categories in the column 'Marital_Status'\n",
        "- i) Group categories 'Married', 'Together' as 'relationship'\n",
        "- ii) Group categories 'Divorced', 'Widow', 'Alone', 'YOLO', and 'Absurd' as 'Single'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb1be519",
      "metadata": {
        "id": "eb1be519"
      },
      "outputs": [],
      "source": [
        "#Before replacing, check the unique values in the Marital_Status column\n",
        "print(df['Marital_Status'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace [Together,Married] as Relationship\n",
        "df['Marital_Status'] = df['Marital_Status'].replace(['Together','Married'],'Relationship')\n",
        "\n",
        "#Replace [Divorced,Widow,Alone,YOLO,Absurd] as Single\n",
        "df['Marital_Status'] = df['Marital_Status'].replace(['Divorced','Widow','Alone','YOLO','Absurd'],'Single')\n",
        "print(df['Marital_Status'].unique())"
      ],
      "metadata": {
        "id": "mVzxqgBrbkCI"
      },
      "id": "mVzxqgBrbkCI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After grouping, now there is only two unique values, Single and Relationship"
      ],
      "metadata": {
        "id": "jV_fMd-RbwkE"
      },
      "id": "jV_fMd-RbwkE"
    },
    {
      "cell_type": "markdown",
      "id": "9566bfbe",
      "metadata": {
        "id": "9566bfbe"
      },
      "source": [
        "### 7. Group the columns 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', and 'MntGoldProds' as 'Total_Expenses'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c3fa800",
      "metadata": {
        "id": "3c3fa800"
      },
      "outputs": [],
      "source": [
        "# Group the columns 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', and 'MntGoldProds' as 'Total_Expenses'\n",
        "df['Total_Expenses'] = df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf0cd083",
      "metadata": {
        "id": "bf0cd083"
      },
      "source": [
        "### 8. Group the columns 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', and 'NumDealsPurchases' as 'Num_Total_Purchases'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c535ede",
      "metadata": {
        "id": "9c535ede"
      },
      "outputs": [],
      "source": [
        "# Group the columns 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', and 'NumDealsPurchases' as 'Num_Total_Purchases'\n",
        "df['Num_Total_Purchases'] = df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases'] + df['NumDealsPurchases'] + df['NumWebVisitsMonth']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52d2dca5",
      "metadata": {
        "id": "52d2dca5"
      },
      "source": [
        "### 9. Group the columns 'Kidhome' and 'Teenhome' as 'Kids'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c861a1",
      "metadata": {
        "id": "f7c861a1"
      },
      "outputs": [],
      "source": [
        "#Group the columsn 'Kidhome' and 'Teenhome' as 'Kids'\n",
        "df['Kids'] = df['Kidhome'] + df['Teenhome']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36f67474",
      "metadata": {
        "id": "36f67474"
      },
      "source": [
        "### 10. Group columns 'AcceptedCmp1 , 2 , 3 , 4, 5' and 'Response' as 'TotalAcceptedCmp'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc9109f",
      "metadata": {
        "id": "ecc9109f"
      },
      "outputs": [],
      "source": [
        "# Group columns 'AcceptedCmp1 , 2 , 3 , 4, 5' and 'Response' as 'TotalAcceptedCmp'\n",
        "df['TotalAcceptedCmp'] = df['AcceptedCmp1'] + df['AcceptedCmp2'] + df['AcceptedCmp3'] + df['AcceptedCmp4'] + df['AcceptedCmp5'] + df['Response']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886bfb08",
      "metadata": {
        "id": "886bfb08"
      },
      "source": [
        "### 11. Drop those columns which we have used above for obtaining new features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e853e663",
      "metadata": {
        "id": "e853e663"
      },
      "outputs": [],
      "source": [
        "df=df.drop(columns=['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds','NumWebVisitsMonth','NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumDealsPurchases','Kidhome', 'Teenhome','AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5','Response'],axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4225ced7",
      "metadata": {
        "id": "4225ced7"
      },
      "source": [
        "### 12. Extract 'age' using the column 'Year_Birth' and then drop the column 'Year_birth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d517611e",
      "metadata": {
        "id": "d517611e"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "df['Age'] = datetime.now().year - df['Year_Birth']\n",
        "\n",
        "#drop the Year_Birth Column\n",
        "df.drop('Year_Birth',axis=1,inplace=True)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d3c92d",
      "metadata": {
        "id": "f2d3c92d"
      },
      "source": [
        "### 13. Encode the categorical variables in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "030cfc32",
      "metadata": {
        "id": "030cfc32"
      },
      "outputs": [],
      "source": [
        "#Encoding\n",
        "categorical_data = ['Education','Marital_Status']\n",
        "lbl = LabelEncoder()\n",
        "for i in categorical_data:\n",
        "    df[i] = lbl.fit_transform(df[i])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9242e36d",
      "metadata": {
        "id": "9242e36d"
      },
      "source": [
        "### 14. Standardize the columns, so that values are in a particular range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72475b68",
      "metadata": {
        "id": "72475b68"
      },
      "outputs": [],
      "source": [
        "df1 = df.copy()\n",
        "scaled_features = StandardScaler().fit_transform(df1.values)\n",
        "scaled_features_df = pd.DataFrame(scaled_features, index=df1.index, columns=df1.columns)\n",
        "scaled_features_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d063d2e2",
      "metadata": {
        "id": "d063d2e2"
      },
      "source": [
        "### 15. Apply PCA on the above dataset and determine the number of PCA components to be used so that 90-95% of the variance in data is explained by the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df3c70e",
      "metadata": {
        "id": "6df3c70e"
      },
      "outputs": [],
      "source": [
        "#Generate the Covariance matrix\n",
        "cov_matrix = np.cov(scaled_features.T)\n",
        "cov_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcuate the eigen values and eigen vectors\n",
        "eig_values, eig_vectors = np.linalg.eig(cov_matrix)\n",
        "print('eig_values:','/n',eig_values)\n",
        "print('eig_vectors:','/n',eig_vectors)"
      ],
      "metadata": {
        "id": "F4kcX2ZGSLvE"
      },
      "id": "F4kcX2ZGSLvE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate explained variance and cumulative variance\n",
        "total = sum(eig_values)\n",
        "var_exp = [(i/total)*100 for i in sorted(eig_values,reverse=True)]\n",
        "cum_var_exp = np.cumsum(var_exp)\n",
        "print('Explained Variance: ',var_exp)\n",
        "print('Cummulative Variance Explained: ',cum_var_exp)"
      ],
      "metadata": {
        "id": "2ZXMscazc2EK"
      },
      "id": "2ZXMscazc2EK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scree plot\n",
        "plt.bar(range(10),var_exp,align='center',color='lightgreen',edgecolor='black',label='Explained Variance')\n",
        "plt.step(range(10),cum_var_exp,where='mid',color='red',label='Cummulative Variance Explained')\n",
        "plt.xlabel('Principal Components')\n",
        "plt.ylabel('Explained Variance Ratio')\n",
        "plt.title('Scree Plot')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sRSwulI8c2VF"
      },
      "id": "sRSwulI8c2VF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first 8 principal components are explaining about 95% of the variation.\n",
        "So the optimal prinicipal componenet is 8.\n"
      ],
      "metadata": {
        "id": "Pj6IE4vndEBN"
      },
      "id": "Pj6IE4vndEBN"
    },
    {
      "cell_type": "markdown",
      "id": "b2df19d7",
      "metadata": {
        "id": "b2df19d7"
      },
      "source": [
        "### 16. Apply K-means clustering and segment the data (Use PCA transformed data for clustering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3a8bb4c",
      "metadata": {
        "id": "a3a8bb4c"
      },
      "outputs": [],
      "source": [
        "#Using the dimensions obtained from PCA to apply clustering\n",
        "pca = PCA(n_components=8)\n",
        "pca_df = pd.DataFrame(pca.fit_transform(scaled_features_df),columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8'])\n",
        "pca_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Kmeans Clustering using PCA transformed data\n",
        "#finding optimal K value using elbow plot\n",
        "cluster_errors = []\n",
        "cluster_range = range(2,15)\n",
        "for num_clusters in cluster_range:\n",
        "    clusters = KMeans(num_clusters,random_state=100)\n",
        "    clusters.fit(pca_df)\n",
        "    cluster_errors.append(clusters.inertia_)\n",
        "\n",
        "#Creating a df of number of clusters and cluster_errors\n",
        "cluster_df = pd.DataFrame({'num_clusters':cluster_range,'cluster_errors':cluster_errors})\n",
        "\n",
        "#Elbow plot\n",
        "plt.figure(figsize=[15,5])\n",
        "plt.plot(cluster_df['num_clusters'],cluster_df['cluster_errors'],marker='o',color='b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n8rxfINlURry"
      },
      "id": "n8rxfINlURry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   At the inertia drastically decreases.\n",
        "*   Hence optimal clusters at K=3.\n"
      ],
      "metadata": {
        "id": "4r77VT0hddGX"
      },
      "id": "4r77VT0hddGX"
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying KMeans clustering for the optimal number of clusters obtained.\n",
        "kmeans = KMeans(n_clusters=3, random_state=100)\n",
        "kmeans.fit(pca_df)"
      ],
      "metadata": {
        "id": "ptQXoq2HdmzF"
      },
      "id": "ptQXoq2HdmzF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the df of labels\n",
        "label = pd.DataFrame(kmeans.labels_,columns=['Label'])"
      ],
      "metadata": {
        "id": "Fv7BSCaQfJWc"
      },
      "id": "Fv7BSCaQfJWc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## joining the label dataframe to the pca_df dataframe\n",
        "kmeans_df = pca_df.join(label)\n",
        "kmeans_df.head()"
      ],
      "metadata": {
        "id": "biijLyl1fQhK"
      },
      "id": "biijLyl1fQhK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_df['Label'].value_counts()"
      ],
      "metadata": {
        "id": "QdW0GcWFfWCB"
      },
      "id": "QdW0GcWFfWCB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing the clusters formed using scatter plot\n",
        "sns.scatterplot(x=kmeans_df['PC1'],y=kmeans_df['PC2'],hue='Label',data=kmeans_df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jKdp4dK_fQqM"
      },
      "id": "jKdp4dK_fQqM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d8463aed",
      "metadata": {
        "id": "d8463aed"
      },
      "source": [
        "### 17. Apply Agglomerative clustering and segment the data (Use Original data for clustering), and perform cluster analysis by doing bivariate analysis between the cluster label and different features and write your observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5ca165b",
      "metadata": {
        "id": "b5ca165b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[18,5])\n",
        "merg = linkage(scaled_features, method='ward')\n",
        "dendrogram(merg, leaf_rotation=90,)\n",
        "plt.xlabel('Datapoints')\n",
        "plt.ylabel('Euclidean distance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score"
      ],
      "metadata": {
        "id": "Dc807TWHVa6A"
      },
      "id": "Dc807TWHVa6A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2,15):\n",
        "    hier = AgglomerativeClustering(n_clusters=i)\n",
        "    hier = hier.fit(scaled_features_df)\n",
        "    labels= hier.fit_predict(scaled_features_df)\n",
        "    print(i,silhouette_score(scaled_features_df,label))"
      ],
      "metadata": {
        "id": "oAzMypzIdxBp"
      },
      "id": "oAzMypzIdxBp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*    The highest score is for clusters 3\n",
        "*   K=3 is the optimal cluster size\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6p-YS8rxebqB"
      },
      "id": "6p-YS8rxebqB"
    },
    {
      "cell_type": "code",
      "source": [
        "## Building hierarchical clustering model using the optimal clusters as 3 using original data\n",
        "hie_cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage = 'ward')\n",
        "hie_cluster_model = hie_cluster.fit(scaled_features_df)"
      ],
      "metadata": {
        "id": "pLo78L0-eb-E"
      },
      "id": "pLo78L0-eb-E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## creating a dataframe of the labels\n",
        "df_label1 = pd.DataFrame(hie_cluster_model.labels_,columns=['Labels'])\n",
        "df_label1.head(5)"
      ],
      "metadata": {
        "id": "LFL4p0ayecPD"
      },
      "id": "LFL4p0ayecPD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## joining the label dataframe with unscaled initial cleaned dataframe.(dfc)\n",
        "\n",
        "df_hier = dfc.join(df_label1)\n",
        "df_hier.head(5)"
      ],
      "metadata": {
        "id": "LA4W_w56gtzr"
      },
      "id": "LA4W_w56gtzr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "797a5ecd",
      "metadata": {
        "id": "797a5ecd"
      },
      "source": [
        "### Visualization and Interpretation of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e75760",
      "metadata": {
        "id": "d1e75760"
      },
      "outputs": [],
      "source": [
        "sns.barplot(df_hier['Labels'],df_hier['Total_Expenses'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Total Expenses his much higher for cluster 0 as compared to cluster 1 and 2\n"
      ],
      "metadata": {
        "id": "ZCimMfgjkUyK"
      },
      "id": "ZCimMfgjkUyK"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(df_hier['Labels'],df_hier['Income'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9Q3rqnPQkVMt"
      },
      "id": "9Q3rqnPQkVMt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Cluster 0 is having high income group followed by cluster 2 and cluster 1 is having lower income group\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f8pJAkAbkfhC"
      },
      "id": "f8pJAkAbkfhC"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df_hier['Marital_Status'],hue='Labels',data=df_hier)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FvEYmjOrkpl8"
      },
      "id": "FvEYmjOrkpl8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   We can observe that most of the customers who are in a relationship comes under cluster 0\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sayQs123kuOY"
      },
      "id": "sayQs123kuOY"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(df_hier['Labels'],df_hier['Num_Total_Purchases'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2826MbT5kug6"
      },
      "id": "2826MbT5kug6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The total number of purchases is also much higher for customers in cluster 0 compared to cluster 1 and 2.\n"
      ],
      "metadata": {
        "id": "wsFh6NSSku1f"
      },
      "id": "wsFh6NSSku1f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "Customers belonging to cluster 0 does maximum purchases, has spent maximum amount and have maximum income\n",
        "Where as customers belonging to cluster 1 has the least total expenses , minimum balances and does minimum purchases compared to other 2 clusters\n",
        "Customers belonging to cluster 2 does average purchanges and has average income\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rKnFr4uhf3DG"
      },
      "id": "rKnFr4uhf3DG"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zPCWAQRMlEjF"
      },
      "id": "zPCWAQRMlEjF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "36afd95b",
      "metadata": {
        "id": "36afd95b"
      },
      "source": [
        "-----\n",
        "## Happy Learning\n",
        "-----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "36afd95b"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}